{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# from src.model import Model\n",
    "from utils.parser import parse_arguments\n",
    "from models.decomposer import Decomposer\n",
    "from data.siar_data import SIARDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_arguments()\n",
    "config = OmegaConf.load(args.config)\n",
    "# wandb_logger = WandbLogger(config=config, project=\"HTCV\")\n",
    "\n",
    "siar = SIARDataModule(config.data.dir, config.train.batch_size)\n",
    "siar.setup(\"train\", config.train.debug)\n",
    "\n",
    "model = Decomposer(config=config.model) # --- output: (B, C(768), D(5), H(8), H(8))\n",
    "### add a new layer to the model to predict gaussian noise (B, 3, 5, 8, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "diffuser = UNet2DModel(\n",
    "    sample_size=config.model.sample_size,  # the target image resolution\n",
    "    in_channels=config.model.input_dim,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=config.model.output_dim,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(\n",
    "        64,\n",
    "        128,\n",
    "        128,\n",
    "    ),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"UpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "    ),\n",
    ").to(device)\n",
    "# scheduler = DDPMScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/01r1yj4x4ys2q6fkfnhjgg340000gn/T/ipykernel_18841/2301952990.py:17: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  (1, diffuser.in_channels, height // 8, width // 8),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = 1\n",
    "\n",
    "width = 512\n",
    "height = 512\n",
    "\n",
    "generator = torch.Generator(device=device)\n",
    "\n",
    "latents = None\n",
    "seeds = []\n",
    "for _ in range(num_images):\n",
    "    # Get a new random seed, store it and use it as the generator state\n",
    "    seed = generator.seed()\n",
    "    seeds.append(seed)\n",
    "    generator = generator.manual_seed(seed)\n",
    "    \n",
    "    image_latents = torch.randn(\n",
    "        (1, diffuser.in_channels, height // 8, width // 8),\n",
    "        generator = generator,\n",
    "        device = device\n",
    "    )\n",
    "    latents = image_latents if latents is None else torch.cat((latents, image_latents))\n",
    "    \n",
    "# latents should have shape (4, 4, 64, 64) in this case\n",
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
